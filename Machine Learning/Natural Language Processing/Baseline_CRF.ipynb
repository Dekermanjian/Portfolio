{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ae4df74-763b-429d-ae47-d9d5597fc58c",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa66cd27-3606-446b-bfa7-b00ad334d964",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import json\n",
    "from collections import Counter\n",
    "import random\n",
    "import sys\n",
    "from joblib import dump, load\n",
    "\n",
    "import scipy.stats\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "#from sklearn.linear_model import perceptron, SGDClassifier, PassiveAggressiveClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report, make_scorer, f1_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import metrics\n",
    "from sklearn_crfsuite import scorers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af05b6d-549a-4e85-815f-e2995d5b40cf",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25dbdd30-49e8-4902-ad61-66986e373fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = pd.read_csv(\"Data/query1_2-manualCurate.csv\")[\"title_abstract\"]\n",
    "# text2 = pd.read_csv(\"Data/query2_manualCurate.csv\")[\"title_abstract\"]\n",
    "# text = text[0:300]\n",
    "#text = pd.concat([text[0:300],text2]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c201f75b-95dc-4368-8642-0230a67de6e4",
   "metadata": {},
   "source": [
    "# Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49d81807-642a-4361-99ee-3092a8b5926b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to process the data\n",
    "def processText(text):\n",
    "    # Get abstracts into one continuous string\n",
    "    text = text.str.cat()\n",
    "    # Tokenize the string object by word\n",
    "    text = word_tokenize(text)\n",
    "    # Remove stop words\n",
    "    stop = set(stopwords.words('english'))\n",
    "    text = [w for w in text if not w in stop]\n",
    "    # Tag each word by the appropriate part of speech (POS) tag\n",
    "    text = pos_tag(text)\n",
    "    # Reshape the data into a dataframe\n",
    "    text = pd.DataFrame(text, columns=['word','POS'])\n",
    "    return(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c45d5860-761c-484f-8f55-fb240d533f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = processText(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d1bca9-0d6c-4c6d-a055-0ee3a6758866",
   "metadata": {},
   "source": [
    "# Tag text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a9e76c5-9e5d-4ea2-acaf-a57547d35149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to detect metabolomics software tools, so we will tag some tools\n",
    "tags = pd.read_csv(\"Data/CuratedTools.csv\")\n",
    "toolsToTag = tags.CuratedTools.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c83907c-417a-4b17-999a-30b6628fba7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tag the training data\n",
    "df[\"label\"] = [\"T\" if x in toolsToTag else \"O\" for x in df.word]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9ea556-f26e-460a-906c-09b6b1f547f8",
   "metadata": {},
   "source": [
    "# Identify sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60ce2d49-43d1-4f61-99c4-6bd143047a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that identifies where sentences begin/end\n",
    "def identSentence(textDf):\n",
    "    # start at sentence 1\n",
    "    n_sent = 1\n",
    "    sents = [] # init empty array to wholed sentence identifiers\n",
    "    # Loop through text incrementing n_sent after each period\n",
    "    for word in textDf.word:\n",
    "        if word == \".\":\n",
    "            sents.append(n_sent)\n",
    "            n_sent += 1\n",
    "        else:\n",
    "            sents.append(np.nan) # If we are still before the end of the sentence label it as NA\n",
    "    textDf['Sent_id'] = sents # Generate a column of the sentences \n",
    "    textDf['Sent_id'] = textDf['Sent_id'].bfill() # back fill the NAs to get the correct sentence IDs\n",
    "    return(textDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17f6938e-622a-4680-ab7b-ad708cee3b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = identSentence(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d5b7283-0dfd-4eea-be17-44bf3ea1902c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>POS</th>\n",
       "      <th>label</th>\n",
       "      <th>Sent_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MetExplore</td>\n",
       "      <td>NN</td>\n",
       "      <td>T</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>:</td>\n",
       "      <td>:</td>\n",
       "      <td>O</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>collaborative</td>\n",
       "      <td>JJ</td>\n",
       "      <td>O</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>edition</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>exploration</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            word POS label  Sent_id\n",
       "0     MetExplore  NN     T      1.0\n",
       "1              :   :     O      1.0\n",
       "2  collaborative  JJ     O      1.0\n",
       "3        edition  NN     O      1.0\n",
       "4    exploration  NN     O      1.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16d1ab7-f54b-44f2-aae4-4bb56386d19f",
   "metadata": {},
   "source": [
    "# Get Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b1d48f9-c5ef-40f6-b7a1-4333adfd2f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceGetter(object):\n",
    "    def __init__(self, data):\n",
    "        self.n_sent = 1\n",
    "        self.data = data\n",
    "        self.empty = False\n",
    "        agg_func = lambda s: [(w,p,t) for w, p, t in zip(s['word'].values.tolist(),\n",
    "                                                         s['POS'].values.tolist(),\n",
    "                                                         s['label'].values.tolist())]\n",
    "        self.grouped = self.data.groupby('Sent_id').apply(agg_func)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "    def get_next(self):\n",
    "        try:\n",
    "            s = self.grouped['Sentence: {}:'.format(self.n_sent)]\n",
    "            self.n_sent += 1\n",
    "            return s\n",
    "        except:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ece063-46d2-4dae-9c34-d885b451914a",
   "metadata": {},
   "source": [
    "# Build CRF Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22b5996f-7091-4dd5-bdd9-d6e0ad8806a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def camel(word):\n",
    "    return word != word.lower() and word != word.upper() and word.istitle() != True and \"_\" not in word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "003d7ed6-b732-4fa9-ac8a-fdac43443656",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_features(sent, i):\n",
    "        word = sent[i][0]\n",
    "        postag = sent[i][1]\n",
    "        \n",
    "        features = {\n",
    "            'bias': 1.0,\n",
    "            'word': word,\n",
    "            #'word[-3:]': word[-3:],\n",
    "            #'word[-2:]': word[-2:],\n",
    "            'word.isupper()': word.isupper(),\n",
    "            'num_upper_chars': sum(map(str.isupper, word)),\n",
    "            'camelCase': camel(word),\n",
    "            'word.istitle()': word.istitle(),\n",
    "            'word.isdigit()': word.isdigit(),\n",
    "            'postag': postag,\n",
    "            #'postag[:2]': postag[:2],\n",
    "        }\n",
    "        if i > 0:\n",
    "            word1 = sent[i-1][0]\n",
    "            postag1 = sent[i-1][1]\n",
    "            features.update({\n",
    "                '-1:word.lower()': word1.lower(),\n",
    "                '-1:word.istitle()': word1.istitle(),\n",
    "                '-1:word.isupper()': word1.isupper(),\n",
    "                '-1:postag': postag1,\n",
    "                #'-1:postag[:2]': postag1[:2],\n",
    "            })\n",
    "        else:\n",
    "            features['BOS'] = True\n",
    "        if i < len(sent)-1:\n",
    "            word1 = sent[i+1][0]\n",
    "            postag1 = sent[i+1][1]\n",
    "            features.update({\n",
    "                '+1word.lower()': word1.lower(),\n",
    "                '+1word.istitle()': word1.istitle(),\n",
    "                '+1word.isupper()': word1.isupper(),\n",
    "                '+1postag': postag1,\n",
    "                #'+1postag[:2]': postag1[:2],\n",
    "            })\n",
    "        else:\n",
    "            features['EOS'] = True\n",
    "        return features\n",
    "\n",
    "def sent_features(sent):\n",
    "    return [word_features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent_labels(sent):\n",
    "    return [label for token, postag, label in sent]\n",
    "\n",
    "def sent_tokens(sent):\n",
    "    return [token for token, postag, label in sent]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b436fc1-319f-41cb-9fd5-6c88b34471eb",
   "metadata": {},
   "source": [
    "# Implement CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6509cd66-9f09-4b42-9ea8-a1caec0b510b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into sentences\n",
    "getter = SentenceGetter(df)\n",
    "sentences = getter.sentences\n",
    "X = [sent_features(s) for s in sentences]\n",
    "Y = [sent_labels(s) for s in sentences] \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=555, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "249c61a7-0ae1-4d24-a8a8-e29180bfd86c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           T       0.82      0.55      0.66       261\n",
      "\n",
      "   micro avg       0.82      0.55      0.66       261\n",
      "   macro avg       0.82      0.55      0.66       261\n",
      "weighted avg       0.82      0.55      0.66       261\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathandekermanjian/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:72: FutureWarning: Pass labels=['T'] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#Train a CRF model\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm = 'lbfgs',\n",
    "    c1 = 0.1,\n",
    "    c2 = 0.1,\n",
    "    max_iterations = 100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "crf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = crf.predict(X_test)\n",
    "print(metrics.flat_classification_report(y_true = y_test, y_pred = y_pred, labels = ['T']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
