{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3aa8d1a-17c8-4fa7-9a85-e5ab560d3b77",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f3e53ec-6904-4691-87c1-ca6a1ad07600",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sparknlp\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.window import Window\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.base import *\n",
    "from sparknlp.common import *\n",
    "import pyspark.sql.functions as F\n",
    "from sparknlp.training import CoNLL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecefcd4b-4959-4ae3-89ef-a9f5b159f491",
   "metadata": {},
   "source": [
    "# Start Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eeb05f31-c5a6-4f44-961a-b1f5604d962c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = sparknlp.start(gpu=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7692e094-4fd0-4c24-97b8-1dc7c127f3b2",
   "metadata": {},
   "source": [
    "# Load the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba10d66f-5a4d-407f-9c49-2786f491e20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_model = PipelineModel.load(\"NER_model/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce341ea-1de3-42c6-a337-fd23aa98eb38",
   "metadata": {},
   "source": [
    "# Define Processing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e2a69714-fa84-4181-a6ac-c6157170f2a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elmo download started this may take some time.\n",
      "Approximate size to download 334.1 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "# Normalize the text\n",
    "normalizer = (\n",
    "    Normalizer()\n",
    "    .setInputCols(['token'])\n",
    "    .setOutputCol('normalized')\n",
    "    .setLowercase(False)\n",
    "    .setCleanupPatterns([\"[,\\.\\s]\"])\n",
    "#     .setCleanupPatterns([\"[^\\w\\d\\s]\"]) # Removes punctuation\n",
    ")\n",
    "\n",
    "# Get ELMo word embeddings\n",
    "elmo = (\n",
    "    ElmoEmbeddings.pretrained()\n",
    "    .setInputCols(\"sentence\", \"normalized\")\n",
    "    .setOutputCol(\"elmo\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a46917e-8b0a-405d-b473-1682738f6091",
   "metadata": {},
   "source": [
    "# Load and Process Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2e8beb88-a71e-4c79-ab32-08fc007f883b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|                text|            document|            sentence|               token|                 pos|               label|          normalized|                elmo|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|Metabolite identi...|[{document, 0, 71...|[{document, 0, 71...|[{token, 0, 9, Me...|[{pos, 0, 9, NNP,...|[{named_entity, 0...|[{token, 0, 9, Me...|[{word_embeddings...|\n",
      "|Metabolite identi...|[{document, 0, 79...|[{document, 0, 79...|[{token, 0, 9, Me...|[{pos, 0, 9, NNP,...|[{named_entity, 0...|[{token, 0, 9, Me...|[{word_embeddings...|\n",
      "|Various computati...|[{document, 0, 86...|[{document, 0, 86...|[{token, 0, 6, Va...|[{pos, 0, 6, JJ, ...|[{named_entity, 0...|[{token, 0, 6, Va...|[{word_embeddings...|\n",
      "|Fragmentation tre...|[{document, 0, 13...|[{document, 0, 13...|[{token, 0, 12, F...|[{pos, 0, 12, NNP...|[{named_entity, 0...|[{token, 0, 12, F...|[{word_embeddings...|\n",
      "|Machine learning ...|[{document, 0, 14...|[{document, 0, 14...|[{token, 0, 6, Ma...|[{pos, 0, 6, NNP,...|[{named_entity, 0...|[{token, 0, 6, Ma...|[{word_embeddings...|\n",
      "|Here , combine fr...|[{document, 0, 13...|[{document, 0, 13...|[{token, 0, 3, He...|[{pos, 0, 3, RB, ...|[{named_entity, 0...|[{token, 0, 3, He...|[{word_embeddings...|\n",
      "|We introduce fami...|[{document, 0, 14...|[{document, 0, 14...|[{token, 0, 1, We...|[{pos, 0, 1, PRP,...|[{named_entity, 0...|[{token, 0, 1, We...|[{word_embeddings...|\n",
      "|Experiments two l...|[{document, 0, 12...|[{document, 0, 12...|[{token, 0, 10, E...|[{pos, 0, 10, NNS...|[{named_entity, 0...|[{token, 0, 10, E...|[{word_embeddings...|\n",
      "|These improvement...|[{document, 0, 22...|[{document, 0, 22...|[{token, 0, 4, Th...|[{pos, 0, 4, DT, ...|[{named_entity, 0...|[{token, 0, 4, Th...|[{word_embeddings...|\n",
      "|Modern analytical...|[{document, 0, 15...|[{document, 0, 15...|[{token, 0, 5, Mo...|[{pos, 0, 5, NNP,...|[{named_entity, 0...|[{token, 0, 5, Mo...|[{word_embeddings...|\n",
      "|Such techniques c...|[{document, 0, 12...|[{document, 0, 12...|[{token, 0, 3, Su...|[{pos, 0, 3, JJ, ...|[{named_entity, 0...|[{token, 0, 3, Su...|[{word_embeddings...|\n",
      "|However , since d...|[{document, 0, 12...|[{document, 0, 12...|[{token, 0, 6, Ho...|[{pos, 0, 6, RB, ...|[{named_entity, 0...|[{token, 0, 6, Ho...|[{word_embeddings...|\n",
      "|Whilst number fee...|[{document, 0, 16...|[{document, 0, 16...|[{token, 0, 5, Wh...|[{pos, 0, 5, NNP,...|[{named_entity, 0...|[{token, 0, 5, Wh...|[{word_embeddings...|\n",
      "|We present intera...|[{document, 0, 11...|[{document, 0, 11...|[{token, 0, 1, We...|[{pos, 0, 1, PRP,...|[{named_entity, 0...|[{token, 0, 1, We...|[{word_embeddings...|\n",
      "|This presented an...|[{document, 0, 11...|[{document, 0, 11...|[{token, 0, 3, Th...|[{pos, 0, 3, DT, ...|[{named_entity, 0...|[{token, 0, 3, Th...|[{word_embeddings...|\n",
      "|We demonstrate dy...|[{document, 0, 10...|[{document, 0, 10...|[{token, 0, 1, We...|[{pos, 0, 1, PRP,...|[{named_entity, 0...|[{token, 0, 1, We...|[{word_embeddings...|\n",
      "|The software used...|[{document, 0, 15...|[{document, 0, 15...|[{token, 0, 2, Th...|[{pos, 0, 2, DT, ...|[{named_entity, 0...|[{token, 0, 2, Th...|[{word_embeddings...|\n",
      "|Clustering used g...|[{document, 0, 22...|[{document, 0, 22...|[{token, 0, 9, Cl...|[{pos, 0, 9, VBG,...|[{named_entity, 0...|[{token, 0, 9, Cl...|[{word_embeddings...|\n",
      "|To support sessil...|[{document, 0, 10...|[{document, 0, 10...|[{token, 0, 1, To...|[{pos, 0, 1, TO, ...|[{named_entity, 0...|[{token, 0, 1, To...|[{word_embeddings...|\n",
      "|Dynamic changes m...|[{document, 0, 14...|[{document, 0, 14...|[{token, 0, 6, Dy...|[{pos, 0, 6, NNP,...|[{named_entity, 0...|[{token, 0, 6, Dy...|[{word_embeddings...|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test = CoNLL().readDataset(spark, '../../../Natural Language Processing/Data/testingTextProcessed.txt')\n",
    "test = normalizer.fit(test).transform(test)\n",
    "test = elmo.transform(test)\n",
    "test.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407dfe40-5b9f-4c5a-91f3-a8782d1b69a5",
   "metadata": {},
   "source": [
    "# Extract an Abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eb8f15a8-4906-4a1d-aa35-9edfe6da86c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample = test.withColumn(\"id\",F.row_number().over(Window.orderBy(F.monotonically_increasing_id()))) .where(F.col(\"id\").between(35,60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ffcfdd00-ca83-44d1-8419-4d678b63a282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|text                                                                                                                                                                                                                           |\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|contact @ workflow4metabolomics.org.MRMkit : Automated Data Processing Large-Scale Targeted Metabolomics Analysis .                                                                                                            |\n",
      "|MRMkit open-source software package designed automated processing large-scale targeted mass spectrometry-based metabolomics data .                                                                                             |\n",
      "|With improvements automation sample preparation LC-MS analysis , challenging next step fully automate workflow process raw data ensure quality measurements large-scale analysis settings .                                    |\n",
      "|MRMkit capitalizes richness large-sample data capturing peak shapes interference patterns transitions across many samples delivers fully automated , reproducible peak integration results scalable time-efficient manner .    |\n",
      "|In addition fast accurate peak integration , tool also provides reliable data normalization functions quality metrics along visualizations fast data quality evaluation .                                                      |\n",
      "|In addition , MRMkit learns retention time offset patterns user-specified compound classes makes recommendations peak picking multimodal ion chromatograms .                                                                   |\n",
      "|In summary , MRMkit offers highly consistent scalable data processing capacity targeted metabolomics , substantially curtailing time required produce final quantification results LC-MS analysis.Review : toxicometabolomics .|\n",
      "|Metabolomics use toxicology rapidly increasing , particularly owing advances mass spectroscopy , widely used life sciences phenotyping disease states .                                                                        |\n",
      "|Toxicology advantage disease agent , toxicant , available experimental induction metabolomics changes monitored time dose .                                                                                                    |\n",
      "|This review summarizes different technologies employed gives examples use various areas toxicology .                                                                                                                           |\n",
      "|A prominent use metabolomics identification signatures toxicity - patterns metabolite changes predictive hazard manifestation .                                                                                                |\n",
      "|Increasingly , signatures indicative certain hazard manifestation identified , suggesting certain modes action result specific derangements metabolism .                                                                       |\n",
      "|This might enable deduction underlying pathways toxicity , , entirety , form Human Toxome , key concept implementing vision Toxicity Testing 21st century .                                                                    |\n",
      "|This review summarizes current state metabolomics technologies principles , uses toxicology gives thorough overview metabolomics bioinformatics , pathway identification quality assurance .                                   |\n",
      "|In addition , review lays prospects metabolomics application also regulatory context.Bayesian deconvolution quantification metabolites complex 1D NMR spectra using BATMAN .                                                   |\n",
      "|Data processing 1D NMR spectra key bottleneck metabolomic complex-mixture studies , particularly quantitative data individual metabolites required .                                                                           |\n",
      "|We present protocol automated metabolite deconvolution quantification complex NMR spectra using Bayesian automated metabolite analyzer NMR ( BATMAN ) R package .                                                              |\n",
      "|BATMAN models resonances basis user-controllable set templates , specifies chemical shifts , J-couplings relative peak intensities single metabolite .                                                                         |\n",
      "|Peaks allowed shift position slightly spectra , peak widths allowed vary user-specified amounts .                                                                                                                              |\n",
      "|NMR signals captured templates modeled non-parametrically using wavelets .                                                                                                                                                     |\n",
      "|The protocol covers setting user template libraries , optimizing algorithmic input parameters , improving prior information peak positions , quality control evaluation outputs .                                              |\n",
      "|The outputs include relative concentration estimates named metabolites together associated Bayesian uncertainty estimates , well fit remainder spectrum using wavelets .                                                       |\n",
      "|Graphical diagnostics allow user examine quality fit multiple spectra simultaneously .                                                                                                                                         |\n",
      "|This approach offers workflow analyze large numbers spectra expected useful wide range metabolomics studies .                                                                                                                  |\n",
      "|Tools resources metabolomics research community : A 2017-2018 update .                                                                                                                                                         |\n",
      "|The scale MS- NMR-based platforms generate metabolomics datasets research , core , clinical facilities address challenges various sciences-ranging biomedical agricultural-is underappreciated .                               |\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_sample.select('text').show(100,truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4dfbe6-64b2-4e13-95e8-0769f4daf77a",
   "metadata": {},
   "source": [
    "# Apply model on the Extracted Abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c40c47de-7f6d-4000-a06b-e185a4c580c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = ner_model.transform(test_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00124865-14db-4ae6-bca2-52833e5641ca",
   "metadata": {},
   "source": [
    "# Evaluate Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6cb6823e-2529-4b18-81da-e901e57c39a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|ner                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |\n",
      "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|[{named_entity, 0, 6, O, {word -> contact, O -> 1.0, T -> 0.0}, []}, {named_entity, 10, 39, O, {word -> workflow4metabolomicsorgMRMkit, O -> 1.0, T -> 0.0}, []}, {named_entity, 45, 53, O, {word -> Automated, O -> 1.0, T -> 0.0}, []}, {named_entity, 55, 58, O, {word -> Data, O -> 1.0, T -> 0.0}, []}, {named_entity, 60, 69, O, {word -> Processing, O -> 1.0, T -> 0.0}, []}, {named_entity, 71, 80, O, {word -> LargeScale, O -> 1.0, T -> 0.0}, []}, {named_entity, 83, 90, O, {word -> Targeted, O -> 1.0, T -> 0.0}, []}, {named_entity, 92, 103, O, {word -> Metabolomics, O -> 1.0, T -> 0.0}, []}, {named_entity, 105, 112, O, {word -> Analysis, O -> 1.0, T -> 0.0}, []}]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |\n",
      "|[{named_entity, 0, 5, T, {word -> MRMkit, O -> 0.0023, T -> 0.9977}, []}, {named_entity, 7, 16, O, {word -> opensource, O -> 1.0, T -> 0.0}, []}, {named_entity, 19, 26, O, {word -> software, O -> 1.0, T -> 0.0}, []}, {named_entity, 28, 34, O, {word -> package, O -> 1.0, T -> 0.0}, []}, {named_entity, 36, 43, O, {word -> designed, O -> 1.0, T -> 0.0}, []}, {named_entity, 45, 53, O, {word -> automated, O -> 1.0, T -> 0.0}, []}, {named_entity, 55, 64, O, {word -> processing, O -> 1.0, T -> 0.0}, []}, {named_entity, 66, 75, O, {word -> largescale, O -> 1.0, T -> 0.0}, []}, {named_entity, 78, 85, O, {word -> targeted, O -> 1.0, T -> 0.0}, []}, {named_entity, 87, 90, O, {word -> mass, O -> 1.0, T -> 0.0}, []}, {named_entity, 92, 108, O, {word -> spectrometrybased, O -> 1.0, T -> 0.0}, []}, {named_entity, 111, 122, O, {word -> metabolomics, O -> 1.0, T -> 0.0}, []}, {named_entity, 124, 127, O, {word -> data, O -> 1.0, T -> 0.0}, []}]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |\n",
      "|[{named_entity, 0, 3, O, {word -> With, O -> 1.0, T -> 0.0}, []}, {named_entity, 5, 16, O, {word -> improvements, O -> 1.0, T -> 0.0}, []}, {named_entity, 18, 27, O, {word -> automation, O -> 1.0, T -> 0.0}, []}, {named_entity, 29, 34, O, {word -> sample, O -> 1.0, T -> 0.0}, []}, {named_entity, 36, 46, O, {word -> preparation, O -> 1.0, T -> 0.0}, []}, {named_entity, 48, 51, O, {word -> LCMS, O -> 1.0, T -> 0.0}, []}, {named_entity, 54, 61, O, {word -> analysis, O -> 1.0, T -> 0.0}, []}, {named_entity, 65, 75, O, {word -> challenging, O -> 1.0, T -> 0.0}, []}, {named_entity, 77, 80, O, {word -> next, O -> 1.0, T -> 0.0}, []}, {named_entity, 82, 85, O, {word -> step, O -> 1.0, T -> 0.0}, []}, {named_entity, 87, 91, O, {word -> fully, O -> 1.0, T -> 0.0}, []}, {named_entity, 93, 100, O, {word -> automate, O -> 1.0, T -> 0.0}, []}, {named_entity, 102, 109, O, {word -> workflow, O -> 1.0, T -> 0.0}, []}, {named_entity, 111, 117, O, {word -> process, O -> 1.0, T -> 0.0}, []}, {named_entity, 119, 121, O, {word -> raw, O -> 1.0, T -> 0.0}, []}, {named_entity, 123, 126, O, {word -> data, O -> 1.0, T -> 0.0}, []}, {named_entity, 128, 133, O, {word -> ensure, O -> 1.0, T -> 0.0}, []}, {named_entity, 135, 141, O, {word -> quality, O -> 1.0, T -> 0.0}, []}, {named_entity, 143, 154, O, {word -> measurements, O -> 1.0, T -> 0.0}, []}, {named_entity, 156, 165, O, {word -> largescale, O -> 1.0, T -> 0.0}, []}, {named_entity, 168, 175, O, {word -> analysis, O -> 1.0, T -> 0.0}, []}, {named_entity, 177, 184, O, {word -> settings, O -> 1.0, T -> 0.0}, []}]                                                                                                                                                                        |\n",
      "|[{named_entity, 0, 5, T, {word -> MRMkit, O -> 0.0017, T -> 0.9982}, []}, {named_entity, 7, 17, O, {word -> capitalizes, O -> 1.0, T -> 0.0}, []}, {named_entity, 19, 26, O, {word -> richness, O -> 1.0, T -> 0.0}, []}, {named_entity, 28, 38, O, {word -> largesample, O -> 1.0, T -> 0.0}, []}, {named_entity, 41, 44, O, {word -> data, O -> 1.0, T -> 0.0}, []}, {named_entity, 46, 54, O, {word -> capturing, O -> 1.0, T -> 0.0}, []}, {named_entity, 56, 59, O, {word -> peak, O -> 1.0, T -> 0.0}, []}, {named_entity, 61, 66, O, {word -> shapes, O -> 1.0, T -> 0.0}, []}, {named_entity, 68, 79, O, {word -> interference, O -> 1.0, T -> 0.0}, []}, {named_entity, 81, 88, O, {word -> patterns, O -> 1.0, T -> 0.0}, []}, {named_entity, 90, 100, O, {word -> transitions, O -> 1.0, T -> 0.0}, []}, {named_entity, 102, 107, O, {word -> across, O -> 1.0, T -> 0.0}, []}, {named_entity, 109, 112, O, {word -> many, O -> 1.0, T -> 0.0}, []}, {named_entity, 114, 120, O, {word -> samples, O -> 1.0, T -> 0.0}, []}, {named_entity, 122, 129, O, {word -> delivers, O -> 1.0, T -> 0.0}, []}, {named_entity, 131, 135, O, {word -> fully, O -> 1.0, T -> 0.0}, []}, {named_entity, 137, 145, O, {word -> automated, O -> 1.0, T -> 0.0}, []}, {named_entity, 149, 160, O, {word -> reproducible, O -> 1.0, T -> 0.0}, []}, {named_entity, 162, 165, O, {word -> peak, O -> 1.0, T -> 0.0}, []}, {named_entity, 167, 177, O, {word -> integration, O -> 1.0, T -> 0.0}, []}, {named_entity, 179, 185, O, {word -> results, O -> 1.0, T -> 0.0}, []}, {named_entity, 187, 194, O, {word -> scalable, O -> 1.0, T -> 0.0}, []}, {named_entity, 196, 208, O, {word -> timeefficient, O -> 1.0, T -> 0.0}, []}, {named_entity, 211, 216, O, {word -> manner, O -> 1.0, T -> 0.0}, []}]|\n",
      "|[{named_entity, 0, 1, O, {word -> In, O -> 1.0, T -> 0.0}, []}, {named_entity, 3, 10, O, {word -> addition, O -> 1.0, T -> 0.0}, []}, {named_entity, 12, 15, O, {word -> fast, O -> 1.0, T -> 0.0}, []}, {named_entity, 17, 24, O, {word -> accurate, O -> 1.0, T -> 0.0}, []}, {named_entity, 26, 29, O, {word -> peak, O -> 1.0, T -> 0.0}, []}, {named_entity, 31, 41, O, {word -> integration, O -> 1.0, T -> 0.0}, []}, {named_entity, 45, 48, O, {word -> tool, O -> 1.0, T -> 0.0}, []}, {named_entity, 50, 53, O, {word -> also, O -> 1.0, T -> 0.0}, []}, {named_entity, 55, 62, O, {word -> provides, O -> 1.0, T -> 0.0}, []}, {named_entity, 64, 71, O, {word -> reliable, O -> 1.0, T -> 0.0}, []}, {named_entity, 73, 76, O, {word -> data, O -> 1.0, T -> 0.0}, []}, {named_entity, 78, 90, O, {word -> normalization, O -> 1.0, T -> 0.0}, []}, {named_entity, 92, 100, O, {word -> functions, O -> 1.0, T -> 0.0}, []}, {named_entity, 102, 108, O, {word -> quality, O -> 1.0, T -> 0.0}, []}, {named_entity, 110, 116, O, {word -> metrics, O -> 1.0, T -> 0.0}, []}, {named_entity, 118, 122, O, {word -> along, O -> 1.0, T -> 0.0}, []}, {named_entity, 124, 137, O, {word -> visualizations, O -> 1.0, T -> 0.0}, []}, {named_entity, 139, 142, O, {word -> fast, O -> 1.0, T -> 0.0}, []}, {named_entity, 144, 147, O, {word -> data, O -> 1.0, T -> 0.0}, []}, {named_entity, 149, 155, O, {word -> quality, O -> 1.0, T -> 0.0}, []}, {named_entity, 157, 166, O, {word -> evaluation, O -> 1.0, T -> 0.0}, []}]                                                                                                                                                                                                                                                          |\n",
      "|[{named_entity, 0, 1, O, {word -> In, O -> 1.0, T -> 0.0}, []}, {named_entity, 3, 10, O, {word -> addition, O -> 1.0, T -> 0.0}, []}, {named_entity, 14, 19, T, {word -> MRMkit, O -> 8.0E-4, T -> 0.9992}, []}, {named_entity, 21, 26, O, {word -> learns, O -> 1.0, T -> 0.0}, []}, {named_entity, 28, 36, O, {word -> retention, O -> 1.0, T -> 0.0}, []}, {named_entity, 38, 41, O, {word -> time, O -> 1.0, T -> 0.0}, []}, {named_entity, 43, 48, O, {word -> offset, O -> 1.0, T -> 0.0}, []}, {named_entity, 50, 57, O, {word -> patterns, O -> 1.0, T -> 0.0}, []}, {named_entity, 59, 71, O, {word -> userspecified, O -> 1.0, T -> 0.0}, []}, {named_entity, 74, 81, O, {word -> compound, O -> 1.0, T -> 0.0}, []}, {named_entity, 83, 89, O, {word -> classes, O -> 1.0, T -> 0.0}, []}, {named_entity, 91, 95, O, {word -> makes, O -> 1.0, T -> 0.0}, []}, {named_entity, 97, 111, O, {word -> recommendations, O -> 1.0, T -> 0.0}, []}, {named_entity, 113, 116, O, {word -> peak, O -> 1.0, T -> 0.0}, []}, {named_entity, 118, 124, O, {word -> picking, O -> 1.0, T -> 0.0}, []}, {named_entity, 126, 135, O, {word -> multimodal, O -> 1.0, T -> 0.0}, []}, {named_entity, 137, 139, O, {word -> ion, O -> 1.0, T -> 0.0}, []}, {named_entity, 141, 153, O, {word -> chromatograms, O -> 1.0, T -> 0.0}, []}]                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n",
      "|[{named_entity, 0, 1, O, {word -> In, O -> 1.0, T -> 0.0}, []}, {named_entity, 3, 9, O, {word -> summary, O -> 1.0, T -> 0.0}, []}, {named_entity, 13, 18, T, {word -> MRMkit, O -> 7.0E-4, T -> 0.9993}, []}, {named_entity, 20, 25, O, {word -> offers, O -> 1.0, T -> 0.0}, []}, {named_entity, 27, 32, O, {word -> highly, O -> 1.0, T -> 0.0}, []}, {named_entity, 34, 43, O, {word -> consistent, O -> 1.0, T -> 0.0}, []}, {named_entity, 45, 52, O, {word -> scalable, O -> 1.0, T -> 0.0}, []}, {named_entity, 54, 57, O, {word -> data, O -> 1.0, T -> 0.0}, []}, {named_entity, 59, 68, O, {word -> processing, O -> 1.0, T -> 0.0}, []}, {named_entity, 70, 77, O, {word -> capacity, O -> 1.0, T -> 0.0}, []}, {named_entity, 79, 86, O, {word -> targeted, O -> 1.0, T -> 0.0}, []}, {named_entity, 88, 99, O, {word -> metabolomics, O -> 1.0, T -> 0.0}, []}, {named_entity, 103, 115, O, {word -> substantially, O -> 1.0, T -> 0.0}, []}, {named_entity, 117, 126, O, {word -> curtailing, O -> 1.0, T -> 0.0}, []}, {named_entity, 128, 131, O, {word -> time, O -> 1.0, T -> 0.0}, []}, {named_entity, 133, 140, O, {word -> required, O -> 1.0, T -> 0.0}, []}, {named_entity, 142, 148, O, {word -> produce, O -> 1.0, T -> 0.0}, []}, {named_entity, 150, 154, O, {word -> final, O -> 1.0, T -> 0.0}, []}, {named_entity, 156, 169, O, {word -> quantification, O -> 1.0, T -> 0.0}, []}, {named_entity, 171, 177, O, {word -> results, O -> 1.0, T -> 0.0}, []}, {named_entity, 179, 182, O, {word -> LCMS, O -> 1.0, T -> 0.0}, []}, {named_entity, 185, 198, O, {word -> analysisReview, O -> 1.0, T -> 0.0}, []}, {named_entity, 203, 220, O, {word -> toxicometabolomics, O -> 1.0, T -> 0.0}, []}]                                                                    |\n",
      "|[{named_entity, 0, 11, O, {word -> Metabolomics, O -> 1.0, T -> 0.0}, []}, {named_entity, 13, 15, O, {word -> use, O -> 1.0, T -> 0.0}, []}, {named_entity, 17, 26, O, {word -> toxicology, O -> 1.0, T -> 0.0}, []}, {named_entity, 28, 34, O, {word -> rapidly, O -> 1.0, T -> 0.0}, []}, {named_entity, 36, 45, O, {word -> increasing, O -> 1.0, T -> 0.0}, []}, {named_entity, 49, 60, O, {word -> particularly, O -> 1.0, T -> 0.0}, []}, {named_entity, 62, 66, O, {word -> owing, O -> 1.0, T -> 0.0}, []}, {named_entity, 68, 75, O, {word -> advances, O -> 1.0, T -> 0.0}, []}, {named_entity, 77, 80, O, {word -> mass, O -> 1.0, T -> 0.0}, []}, {named_entity, 82, 93, O, {word -> spectroscopy, O -> 1.0, T -> 0.0}, []}, {named_entity, 97, 102, O, {word -> widely, O -> 1.0, T -> 0.0}, []}, {named_entity, 104, 107, O, {word -> used, O -> 1.0, T -> 0.0}, []}, {named_entity, 109, 112, O, {word -> life, O -> 1.0, T -> 0.0}, []}, {named_entity, 114, 121, O, {word -> sciences, O -> 1.0, T -> 0.0}, []}, {named_entity, 123, 133, O, {word -> phenotyping, O -> 1.0, T -> 0.0}, []}, {named_entity, 135, 141, O, {word -> disease, O -> 1.0, T -> 0.0}, []}, {named_entity, 143, 148, O, {word -> states, O -> 0.9999, T -> 1.0E-4}, []}]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n",
      "|[{named_entity, 0, 9, O, {word -> Toxicology, O -> 1.0, T -> 0.0}, []}, {named_entity, 11, 19, O, {word -> advantage, O -> 1.0, T -> 0.0}, []}, {named_entity, 21, 27, O, {word -> disease, O -> 1.0, T -> 0.0}, []}, {named_entity, 29, 33, O, {word -> agent, O -> 1.0, T -> 0.0}, []}, {named_entity, 37, 44, O, {word -> toxicant, O -> 1.0, T -> 0.0}, []}, {named_entity, 48, 56, O, {word -> available, O -> 1.0, T -> 0.0}, []}, {named_entity, 58, 69, O, {word -> experimental, O -> 1.0, T -> 0.0}, []}, {named_entity, 71, 79, O, {word -> induction, O -> 1.0, T -> 0.0}, []}, {named_entity, 81, 92, O, {word -> metabolomics, O -> 1.0, T -> 0.0}, []}, {named_entity, 94, 100, O, {word -> changes, O -> 1.0, T -> 0.0}, []}, {named_entity, 102, 110, O, {word -> monitored, O -> 1.0, T -> 0.0}, []}, {named_entity, 112, 115, O, {word -> time, O -> 1.0, T -> 0.0}, []}, {named_entity, 117, 120, O, {word -> dose, O -> 1.0, T -> 0.0}, []}]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |\n",
      "|[{named_entity, 0, 3, O, {word -> This, O -> 1.0, T -> 0.0}, []}, {named_entity, 5, 10, O, {word -> review, O -> 1.0, T -> 0.0}, []}, {named_entity, 12, 21, O, {word -> summarizes, O -> 1.0, T -> 0.0}, []}, {named_entity, 23, 31, O, {word -> different, O -> 1.0, T -> 0.0}, []}, {named_entity, 33, 44, O, {word -> technologies, O -> 1.0, T -> 0.0}, []}, {named_entity, 46, 53, O, {word -> employed, O -> 1.0, T -> 0.0}, []}, {named_entity, 55, 59, O, {word -> gives, O -> 1.0, T -> 0.0}, []}, {named_entity, 61, 68, O, {word -> examples, O -> 1.0, T -> 0.0}, []}, {named_entity, 70, 72, O, {word -> use, O -> 1.0, T -> 0.0}, []}, {named_entity, 74, 80, O, {word -> various, O -> 1.0, T -> 0.0}, []}, {named_entity, 82, 86, O, {word -> areas, O -> 1.0, T -> 0.0}, []}, {named_entity, 88, 97, O, {word -> toxicology, O -> 1.0, T -> 0.0}, []}]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |\n",
      "|[{named_entity, 0, 0, O, {word -> A, O -> 1.0, T -> 0.0}, []}, {named_entity, 2, 10, O, {word -> prominent, O -> 1.0, T -> 0.0}, []}, {named_entity, 12, 14, O, {word -> use, O -> 1.0, T -> 0.0}, []}, {named_entity, 16, 27, O, {word -> metabolomics, O -> 1.0, T -> 0.0}, []}, {named_entity, 29, 42, O, {word -> identification, O -> 1.0, T -> 0.0}, []}, {named_entity, 44, 53, O, {word -> signatures, O -> 1.0, T -> 0.0}, []}, {named_entity, 55, 62, O, {word -> toxicity, O -> 1.0, T -> 0.0}, []}, {named_entity, 66, 73, O, {word -> patterns, O -> 1.0, T -> 0.0}, []}, {named_entity, 75, 84, O, {word -> metabolite, O -> 1.0, T -> 0.0}, []}, {named_entity, 86, 92, O, {word -> changes, O -> 1.0, T -> 0.0}, []}, {named_entity, 94, 103, O, {word -> predictive, O -> 1.0, T -> 0.0}, []}, {named_entity, 105, 110, O, {word -> hazard, O -> 1.0, T -> 0.0}, []}, {named_entity, 112, 124, O, {word -> manifestation, O -> 1.0, T -> 0.0}, []}]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |\n",
      "|[{named_entity, 0, 11, O, {word -> Increasingly, O -> 1.0, T -> 0.0}, []}, {named_entity, 15, 24, O, {word -> signatures, O -> 1.0, T -> 0.0}, []}, {named_entity, 26, 35, O, {word -> indicative, O -> 1.0, T -> 0.0}, []}, {named_entity, 37, 43, O, {word -> certain, O -> 1.0, T -> 0.0}, []}, {named_entity, 45, 50, O, {word -> hazard, O -> 1.0, T -> 0.0}, []}, {named_entity, 52, 64, O, {word -> manifestation, O -> 1.0, T -> 0.0}, []}, {named_entity, 66, 75, O, {word -> identified, O -> 1.0, T -> 0.0}, []}, {named_entity, 79, 88, O, {word -> suggesting, O -> 1.0, T -> 0.0}, []}, {named_entity, 90, 96, O, {word -> certain, O -> 1.0, T -> 0.0}, []}, {named_entity, 98, 102, O, {word -> modes, O -> 1.0, T -> 0.0}, []}, {named_entity, 104, 109, O, {word -> action, O -> 1.0, T -> 0.0}, []}, {named_entity, 111, 116, O, {word -> result, O -> 1.0, T -> 0.0}, []}, {named_entity, 118, 125, O, {word -> specific, O -> 1.0, T -> 0.0}, []}, {named_entity, 127, 138, O, {word -> derangements, O -> 1.0, T -> 0.0}, []}, {named_entity, 140, 149, O, {word -> metabolism, O -> 1.0, T -> 0.0}, []}]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |\n",
      "|[{named_entity, 0, 3, O, {word -> This, O -> 1.0, T -> 0.0}, []}, {named_entity, 5, 9, O, {word -> might, O -> 1.0, T -> 0.0}, []}, {named_entity, 11, 16, O, {word -> enable, O -> 1.0, T -> 0.0}, []}, {named_entity, 18, 26, O, {word -> deduction, O -> 1.0, T -> 0.0}, []}, {named_entity, 28, 37, O, {word -> underlying, O -> 1.0, T -> 0.0}, []}, {named_entity, 39, 46, O, {word -> pathways, O -> 1.0, T -> 0.0}, []}, {named_entity, 48, 55, O, {word -> toxicity, O -> 1.0, T -> 0.0}, []}, {named_entity, 61, 68, O, {word -> entirety, O -> 1.0, T -> 0.0}, []}, {named_entity, 72, 75, O, {word -> form, O -> 1.0, T -> 0.0}, []}, {named_entity, 77, 81, O, {word -> Human, O -> 1.0, T -> 0.0}, []}, {named_entity, 83, 88, O, {word -> Toxome, O -> 0.9817, T -> 0.0183}, []}, {named_entity, 92, 94, O, {word -> key, O -> 1.0, T -> 0.0}, []}, {named_entity, 96, 102, O, {word -> concept, O -> 1.0, T -> 0.0}, []}, {named_entity, 104, 115, O, {word -> implementing, O -> 1.0, T -> 0.0}, []}, {named_entity, 117, 122, O, {word -> vision, O -> 1.0, T -> 0.0}, []}, {named_entity, 124, 131, O, {word -> Toxicity, O -> 1.0, T -> 0.0}, []}, {named_entity, 133, 139, O, {word -> Testing, O -> 1.0, T -> 0.0}, []}, {named_entity, 141, 144, O, {word -> 21st, O -> 1.0, T -> 0.0}, []}, {named_entity, 146, 152, O, {word -> century, O -> 1.0, T -> 0.0}, []}]                                                                                                                                                                                                                                                                                                                                                                                                         |\n",
      "|[{named_entity, 0, 3, O, {word -> This, O -> 1.0, T -> 0.0}, []}, {named_entity, 5, 10, O, {word -> review, O -> 1.0, T -> 0.0}, []}, {named_entity, 12, 21, O, {word -> summarizes, O -> 1.0, T -> 0.0}, []}, {named_entity, 23, 29, O, {word -> current, O -> 1.0, T -> 0.0}, []}, {named_entity, 31, 35, O, {word -> state, O -> 1.0, T -> 0.0}, []}, {named_entity, 37, 48, O, {word -> metabolomics, O -> 1.0, T -> 0.0}, []}, {named_entity, 50, 61, O, {word -> technologies, O -> 1.0, T -> 0.0}, []}, {named_entity, 63, 72, O, {word -> principles, O -> 1.0, T -> 0.0}, []}, {named_entity, 76, 79, O, {word -> uses, O -> 1.0, T -> 0.0}, []}, {named_entity, 81, 90, O, {word -> toxicology, O -> 1.0, T -> 0.0}, []}, {named_entity, 92, 96, O, {word -> gives, O -> 1.0, T -> 0.0}, []}, {named_entity, 98, 105, O, {word -> thorough, O -> 1.0, T -> 0.0}, []}, {named_entity, 107, 114, O, {word -> overview, O -> 1.0, T -> 0.0}, []}, {named_entity, 116, 127, O, {word -> metabolomics, O -> 1.0, T -> 0.0}, []}, {named_entity, 129, 142, O, {word -> bioinformatics, O -> 1.0, T -> 0.0}, []}, {named_entity, 146, 152, O, {word -> pathway, O -> 1.0, T -> 0.0}, []}, {named_entity, 154, 167, O, {word -> identification, O -> 1.0, T -> 0.0}, []}, {named_entity, 169, 175, O, {word -> quality, O -> 1.0, T -> 0.0}, []}, {named_entity, 177, 185, O, {word -> assurance, O -> 1.0, T -> 0.0}, []}]                                                                                                                                                                                                                                                                                                                                                                       |\n",
      "|[{named_entity, 0, 1, O, {word -> In, O -> 1.0, T -> 0.0}, []}, {named_entity, 3, 10, O, {word -> addition, O -> 1.0, T -> 0.0}, []}, {named_entity, 14, 19, O, {word -> review, O -> 1.0, T -> 0.0}, []}, {named_entity, 21, 24, O, {word -> lays, O -> 1.0, T -> 0.0}, []}, {named_entity, 26, 34, O, {word -> prospects, O -> 1.0, T -> 0.0}, []}, {named_entity, 36, 47, O, {word -> metabolomics, O -> 1.0, T -> 0.0}, []}, {named_entity, 49, 59, O, {word -> application, O -> 1.0, T -> 0.0}, []}, {named_entity, 61, 64, O, {word -> also, O -> 1.0, T -> 0.0}, []}, {named_entity, 66, 75, O, {word -> regulatory, O -> 1.0, T -> 0.0}, []}, {named_entity, 77, 91, O, {word -> contextBayesian, O -> 0.8492, T -> 0.1508}, []}, {named_entity, 94, 106, O, {word -> deconvolution, O -> 1.0, T -> 0.0}, []}, {named_entity, 108, 121, O, {word -> quantification, O -> 1.0, T -> 0.0}, []}, {named_entity, 123, 133, O, {word -> metabolites, O -> 1.0, T -> 0.0}, []}, {named_entity, 135, 141, O, {word -> complex, O -> 1.0, T -> 0.0}, []}, {named_entity, 143, 144, O, {word -> 1D, O -> 1.0, T -> 0.0}, []}, {named_entity, 146, 148, O, {word -> NMR, O -> 1.0, T -> 0.0}, []}, {named_entity, 150, 156, O, {word -> spectra, O -> 1.0, T -> 0.0}, []}, {named_entity, 158, 162, O, {word -> using, O -> 1.0, T -> 0.0}, []}, {named_entity, 164, 169, T, {word -> BATMAN, O -> 0.0078, T -> 0.9921}, []}]                                                                                                                                                                                                                                                                                                                                                                        |\n",
      "|[{named_entity, 0, 3, O, {word -> Data, O -> 1.0, T -> 0.0}, []}, {named_entity, 5, 14, O, {word -> processing, O -> 1.0, T -> 0.0}, []}, {named_entity, 16, 17, O, {word -> 1D, O -> 1.0, T -> 0.0}, []}, {named_entity, 19, 21, O, {word -> NMR, O -> 1.0, T -> 0.0}, []}, {named_entity, 23, 29, O, {word -> spectra, O -> 1.0, T -> 0.0}, []}, {named_entity, 31, 33, O, {word -> key, O -> 1.0, T -> 0.0}, []}, {named_entity, 35, 44, O, {word -> bottleneck, O -> 1.0, T -> 0.0}, []}, {named_entity, 46, 56, O, {word -> metabolomic, O -> 1.0, T -> 0.0}, []}, {named_entity, 58, 71, O, {word -> complexmixture, O -> 1.0, T -> 0.0}, []}, {named_entity, 74, 80, O, {word -> studies, O -> 1.0, T -> 0.0}, []}, {named_entity, 84, 95, O, {word -> particularly, O -> 1.0, T -> 0.0}, []}, {named_entity, 97, 108, O, {word -> quantitative, O -> 1.0, T -> 0.0}, []}, {named_entity, 110, 113, O, {word -> data, O -> 1.0, T -> 0.0}, []}, {named_entity, 115, 124, O, {word -> individual, O -> 1.0, T -> 0.0}, []}, {named_entity, 126, 136, O, {word -> metabolites, O -> 1.0, T -> 0.0}, []}, {named_entity, 138, 145, O, {word -> required, O -> 1.0, T -> 0.0}, []}]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |\n",
      "|[{named_entity, 0, 1, O, {word -> We, O -> 1.0, T -> 0.0}, []}, {named_entity, 3, 9, O, {word -> present, O -> 1.0, T -> 0.0}, []}, {named_entity, 11, 18, O, {word -> protocol, O -> 1.0, T -> 0.0}, []}, {named_entity, 20, 28, O, {word -> automated, O -> 1.0, T -> 0.0}, []}, {named_entity, 30, 39, O, {word -> metabolite, O -> 1.0, T -> 0.0}, []}, {named_entity, 41, 53, O, {word -> deconvolution, O -> 1.0, T -> 0.0}, []}, {named_entity, 55, 68, O, {word -> quantification, O -> 1.0, T -> 0.0}, []}, {named_entity, 70, 76, O, {word -> complex, O -> 1.0, T -> 0.0}, []}, {named_entity, 78, 80, O, {word -> NMR, O -> 1.0, T -> 0.0}, []}, {named_entity, 82, 88, O, {word -> spectra, O -> 1.0, T -> 0.0}, []}, {named_entity, 90, 94, O, {word -> using, O -> 1.0, T -> 0.0}, []}, {named_entity, 96, 103, O, {word -> Bayesian, O -> 0.9971, T -> 0.0029}, []}, {named_entity, 105, 113, O, {word -> automated, O -> 1.0, T -> 0.0}, []}, {named_entity, 115, 124, O, {word -> metabolite, O -> 1.0, T -> 0.0}, []}, {named_entity, 126, 133, O, {word -> analyzer, O -> 1.0, T -> 0.0}, []}, {named_entity, 135, 137, O, {word -> NMR, O -> 1.0, T -> 0.0}, []}, {named_entity, 141, 146, T, {word -> BATMAN, O -> 0.0178, T -> 0.9822}, []}, {named_entity, 150, 150, O, {word -> R, O -> 1.0, T -> 0.0}, []}, {named_entity, 152, 158, O, {word -> package, O -> 1.0, T -> 0.0}, []}]                                                                                                                                                                                                                                                                                                                                                                                       |\n",
      "|[{named_entity, 0, 5, T, {word -> BATMAN, O -> 0.003, T -> 0.997}, []}, {named_entity, 7, 12, O, {word -> models, O -> 1.0, T -> 0.0}, []}, {named_entity, 14, 23, O, {word -> resonances, O -> 1.0, T -> 0.0}, []}, {named_entity, 25, 29, O, {word -> basis, O -> 1.0, T -> 0.0}, []}, {named_entity, 31, 46, O, {word -> usercontrollable, O -> 1.0, T -> 0.0}, []}, {named_entity, 49, 51, O, {word -> set, O -> 1.0, T -> 0.0}, []}, {named_entity, 53, 61, O, {word -> templates, O -> 1.0, T -> 0.0}, []}, {named_entity, 65, 73, O, {word -> specifies, O -> 1.0, T -> 0.0}, []}, {named_entity, 75, 82, O, {word -> chemical, O -> 1.0, T -> 0.0}, []}, {named_entity, 84, 89, O, {word -> shifts, O -> 1.0, T -> 0.0}, []}, {named_entity, 93, 102, O, {word -> Jcouplings, O -> 1.0, T -> 0.0}, []}, {named_entity, 105, 112, O, {word -> relative, O -> 1.0, T -> 0.0}, []}, {named_entity, 114, 117, O, {word -> peak, O -> 1.0, T -> 0.0}, []}, {named_entity, 119, 129, O, {word -> intensities, O -> 1.0, T -> 0.0}, []}, {named_entity, 131, 136, O, {word -> single, O -> 1.0, T -> 0.0}, []}, {named_entity, 138, 147, O, {word -> metabolite, O -> 1.0, T -> 0.0}, []}]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |\n",
      "|[{named_entity, 0, 4, O, {word -> Peaks, O -> 0.9999, T -> 1.0E-4}, []}, {named_entity, 6, 12, O, {word -> allowed, O -> 1.0, T -> 0.0}, []}, {named_entity, 14, 18, O, {word -> shift, O -> 1.0, T -> 0.0}, []}, {named_entity, 20, 27, O, {word -> position, O -> 1.0, T -> 0.0}, []}, {named_entity, 29, 36, O, {word -> slightly, O -> 1.0, T -> 0.0}, []}, {named_entity, 38, 44, O, {word -> spectra, O -> 1.0, T -> 0.0}, []}, {named_entity, 48, 51, O, {word -> peak, O -> 1.0, T -> 0.0}, []}, {named_entity, 53, 58, O, {word -> widths, O -> 1.0, T -> 0.0}, []}, {named_entity, 60, 66, O, {word -> allowed, O -> 1.0, T -> 0.0}, []}, {named_entity, 68, 71, O, {word -> vary, O -> 1.0, T -> 0.0}, []}, {named_entity, 73, 85, O, {word -> userspecified, O -> 1.0, T -> 0.0}, []}, {named_entity, 88, 94, O, {word -> amounts, O -> 1.0, T -> 0.0}, []}]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |\n",
      "|[{named_entity, 0, 2, O, {word -> NMR, O -> 1.0, T -> 0.0}, []}, {named_entity, 4, 10, O, {word -> signals, O -> 1.0, T -> 0.0}, []}, {named_entity, 12, 19, O, {word -> captured, O -> 1.0, T -> 0.0}, []}, {named_entity, 21, 29, O, {word -> templates, O -> 1.0, T -> 0.0}, []}, {named_entity, 31, 37, O, {word -> modeled, O -> 1.0, T -> 0.0}, []}, {named_entity, 39, 55, O, {word -> nonparametrically, O -> 1.0, T -> 0.0}, []}, {named_entity, 58, 62, O, {word -> using, O -> 1.0, T -> 0.0}, []}, {named_entity, 64, 71, O, {word -> wavelets, O -> 1.0, T -> 0.0}, []}]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |\n",
      "|[{named_entity, 0, 2, O, {word -> The, O -> 1.0, T -> 0.0}, []}, {named_entity, 4, 11, O, {word -> protocol, O -> 1.0, T -> 0.0}, []}, {named_entity, 13, 18, O, {word -> covers, O -> 1.0, T -> 0.0}, []}, {named_entity, 20, 26, O, {word -> setting, O -> 1.0, T -> 0.0}, []}, {named_entity, 28, 31, O, {word -> user, O -> 1.0, T -> 0.0}, []}, {named_entity, 33, 40, O, {word -> template, O -> 1.0, T -> 0.0}, []}, {named_entity, 42, 50, O, {word -> libraries, O -> 1.0, T -> 0.0}, []}, {named_entity, 54, 63, O, {word -> optimizing, O -> 1.0, T -> 0.0}, []}, {named_entity, 65, 75, O, {word -> algorithmic, O -> 1.0, T -> 0.0}, []}, {named_entity, 77, 81, O, {word -> input, O -> 1.0, T -> 0.0}, []}, {named_entity, 83, 92, O, {word -> parameters, O -> 1.0, T -> 0.0}, []}, {named_entity, 96, 104, O, {word -> improving, O -> 1.0, T -> 0.0}, []}, {named_entity, 106, 110, O, {word -> prior, O -> 1.0, T -> 0.0}, []}, {named_entity, 112, 122, O, {word -> information, O -> 1.0, T -> 0.0}, []}, {named_entity, 124, 127, O, {word -> peak, O -> 1.0, T -> 0.0}, []}, {named_entity, 129, 137, O, {word -> positions, O -> 1.0, T -> 0.0}, []}, {named_entity, 141, 147, O, {word -> quality, O -> 1.0, T -> 0.0}, []}, {named_entity, 149, 155, O, {word -> control, O -> 1.0, T -> 0.0}, []}, {named_entity, 157, 166, O, {word -> evaluation, O -> 1.0, T -> 0.0}, []}, {named_entity, 168, 174, O, {word -> outputs, O -> 1.0, T -> 0.0}, []}]                                                                                                                                                                                                                                                                                                                    |\n",
      "|[{named_entity, 0, 2, O, {word -> The, O -> 1.0, T -> 0.0}, []}, {named_entity, 4, 10, O, {word -> outputs, O -> 1.0, T -> 0.0}, []}, {named_entity, 12, 18, O, {word -> include, O -> 1.0, T -> 0.0}, []}, {named_entity, 20, 27, O, {word -> relative, O -> 1.0, T -> 0.0}, []}, {named_entity, 29, 41, O, {word -> concentration, O -> 1.0, T -> 0.0}, []}, {named_entity, 43, 51, O, {word -> estimates, O -> 1.0, T -> 0.0}, []}, {named_entity, 53, 57, O, {word -> named, O -> 1.0, T -> 0.0}, []}, {named_entity, 59, 69, O, {word -> metabolites, O -> 1.0, T -> 0.0}, []}, {named_entity, 71, 78, O, {word -> together, O -> 1.0, T -> 0.0}, []}, {named_entity, 80, 89, O, {word -> associated, O -> 1.0, T -> 0.0}, []}, {named_entity, 91, 98, O, {word -> Bayesian, O -> 0.9975, T -> 0.0025}, []}, {named_entity, 100, 110, O, {word -> uncertainty, O -> 1.0, T -> 0.0}, []}, {named_entity, 112, 120, O, {word -> estimates, O -> 1.0, T -> 0.0}, []}, {named_entity, 124, 127, O, {word -> well, O -> 1.0, T -> 0.0}, []}, {named_entity, 129, 131, O, {word -> fit, O -> 1.0, T -> 0.0}, []}, {named_entity, 133, 141, O, {word -> remainder, O -> 1.0, T -> 0.0}, []}, {named_entity, 143, 150, O, {word -> spectrum, O -> 1.0, T -> 0.0}, []}, {named_entity, 152, 156, O, {word -> using, O -> 1.0, T -> 0.0}, []}, {named_entity, 158, 165, O, {word -> wavelets, O -> 1.0, T -> 0.0}, []}]                                                                                                                                                                                                                                                                                                                                                                                  |\n",
      "|[{named_entity, 0, 8, O, {word -> Graphical, O -> 1.0, T -> 0.0}, []}, {named_entity, 10, 20, O, {word -> diagnostics, O -> 1.0, T -> 0.0}, []}, {named_entity, 22, 26, O, {word -> allow, O -> 1.0, T -> 0.0}, []}, {named_entity, 28, 31, O, {word -> user, O -> 1.0, T -> 0.0}, []}, {named_entity, 33, 39, O, {word -> examine, O -> 1.0, T -> 0.0}, []}, {named_entity, 41, 47, O, {word -> quality, O -> 1.0, T -> 0.0}, []}, {named_entity, 49, 51, O, {word -> fit, O -> 1.0, T -> 0.0}, []}, {named_entity, 53, 60, O, {word -> multiple, O -> 1.0, T -> 0.0}, []}, {named_entity, 62, 68, O, {word -> spectra, O -> 1.0, T -> 0.0}, []}, {named_entity, 70, 83, O, {word -> simultaneously, O -> 1.0, T -> 0.0}, []}]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |\n",
      "|[{named_entity, 0, 3, O, {word -> This, O -> 1.0, T -> 0.0}, []}, {named_entity, 5, 12, O, {word -> approach, O -> 1.0, T -> 0.0}, []}, {named_entity, 14, 19, O, {word -> offers, O -> 1.0, T -> 0.0}, []}, {named_entity, 21, 28, O, {word -> workflow, O -> 1.0, T -> 0.0}, []}, {named_entity, 30, 36, O, {word -> analyze, O -> 1.0, T -> 0.0}, []}, {named_entity, 38, 42, O, {word -> large, O -> 1.0, T -> 0.0}, []}, {named_entity, 44, 50, O, {word -> numbers, O -> 1.0, T -> 0.0}, []}, {named_entity, 52, 58, O, {word -> spectra, O -> 1.0, T -> 0.0}, []}, {named_entity, 60, 67, O, {word -> expected, O -> 1.0, T -> 0.0}, []}, {named_entity, 69, 74, O, {word -> useful, O -> 1.0, T -> 0.0}, []}, {named_entity, 76, 79, O, {word -> wide, O -> 1.0, T -> 0.0}, []}, {named_entity, 81, 85, O, {word -> range, O -> 1.0, T -> 0.0}, []}, {named_entity, 87, 98, O, {word -> metabolomics, O -> 1.0, T -> 0.0}, []}, {named_entity, 100, 106, O, {word -> studies, O -> 1.0, T -> 0.0}, []}]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |\n",
      "|[{named_entity, 0, 4, O, {word -> Tools, O -> 1.0, T -> 0.0}, []}, {named_entity, 6, 14, O, {word -> resources, O -> 1.0, T -> 0.0}, []}, {named_entity, 16, 27, O, {word -> metabolomics, O -> 1.0, T -> 0.0}, []}, {named_entity, 29, 36, O, {word -> research, O -> 1.0, T -> 0.0}, []}, {named_entity, 38, 46, O, {word -> community, O -> 1.0, T -> 0.0}, []}, {named_entity, 50, 50, O, {word -> A, O -> 1.0, T -> 0.0}, []}, {named_entity, 52, 59, O, {word -> 20172018, O -> 1.0, T -> 0.0}, []}, {named_entity, 62, 67, O, {word -> update, O -> 1.0, T -> 0.0}, []}]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |\n",
      "|[{named_entity, 0, 2, O, {word -> The, O -> 1.0, T -> 0.0}, []}, {named_entity, 4, 8, O, {word -> scale, O -> 1.0, T -> 0.0}, []}, {named_entity, 10, 11, O, {word -> MS, O -> 1.0, T -> 0.0}, []}, {named_entity, 14, 21, O, {word -> NMRbased, O -> 1.0, T -> 0.0}, []}, {named_entity, 24, 32, O, {word -> platforms, O -> 1.0, T -> 0.0}, []}, {named_entity, 34, 41, O, {word -> generate, O -> 1.0, T -> 0.0}, []}, {named_entity, 43, 54, O, {word -> metabolomics, O -> 1.0, T -> 0.0}, []}, {named_entity, 56, 63, O, {word -> datasets, O -> 1.0, T -> 0.0}, []}, {named_entity, 65, 72, O, {word -> research, O -> 1.0, T -> 0.0}, []}, {named_entity, 76, 79, O, {word -> core, O -> 1.0, T -> 0.0}, []}, {named_entity, 83, 90, O, {word -> clinical, O -> 1.0, T -> 0.0}, []}, {named_entity, 92, 101, O, {word -> facilities, O -> 1.0, T -> 0.0}, []}, {named_entity, 103, 109, O, {word -> address, O -> 1.0, T -> 0.0}, []}, {named_entity, 111, 120, O, {word -> challenges, O -> 1.0, T -> 0.0}, []}, {named_entity, 122, 128, O, {word -> various, O -> 1.0, T -> 0.0}, []}, {named_entity, 130, 144, O, {word -> sciencesranging, O -> 1.0, T -> 0.0}, []}, {named_entity, 147, 156, O, {word -> biomedical, O -> 1.0, T -> 0.0}, []}, {named_entity, 158, 171, O, {word -> agriculturalis, O -> 1.0, T -> 0.0}, []}, {named_entity, 174, 189, O, {word -> underappreciated, O -> 1.0, T -> 0.0}, []}]                                                                                                                                                                                                                                                                                                                                                                        |\n",
      "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict.select('ner').show(100,truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20af46b5-6e6b-462b-9e13-25a0d29def7d",
   "metadata": {},
   "source": [
    "# Apply to all Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "58be0f42-fab4-47d9-98a2-3650ef7daf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = ner_model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "22426a22-5669-40f9-abd3-b562f09ef97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = (\n",
    "    predictions\n",
    "    .select(F.explode(F.arrays_zip('token.result','label.result', 'ner.result', 'ner.metadata')).alias('cols'))\n",
    "    .select(F.col('cols.0').alias('word'),\n",
    "            F.col('cols.1').alias('Truth'),\n",
    "            F.col('cols.2').alias('Prediction'),\n",
    "            F.col('cols.3.O').alias('Confidence O'),\n",
    "            F.col('cols.3.T').alias('Confidence T'))\n",
    "    .withColumn('Confidence', F.when(F.col('Confidence O')>F.col('Confidence T'), F.col('Confidence O')).otherwise(F.col('Confidence T')))\n",
    "    .select('word','Truth','Prediction','Confidence')\n",
    "    .dropna()\n",
    "    .dropDuplicates(['word', 'Prediction'])\n",
    "    .orderBy(['word','Truth','Prediction'], ascending=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3194232f-c971-444b-9930-93aded9573bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_PDF = predictions.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ce7855f7-66bf-45e6-b7c7-817577dfdf79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2563, 4)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_PDF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bb130911-7491-4020-b371-abca63e447e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Truth</th>\n",
       "      <th>Prediction</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">O</th>\n",
       "      <th>O</th>\n",
       "      <td>2441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T</th>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">T</th>\n",
       "      <th>O</th>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T</th>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  word\n",
       "Truth Prediction      \n",
       "O     O           2441\n",
       "      T             48\n",
       "T     O             41\n",
       "      T             33"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_PDF[['Truth','Prediction','word']].groupby(['Truth', 'Prediction']).count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
